{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print iterations progress\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ'):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    DEFAULT_VIDEO_PATH = \"test.mp4\"\n",
    "    \n",
    "    # Count frame per prediction\n",
    "    WINDOW_SIZE = 30\n",
    "    \n",
    "    # Interval per last windows frame and prediction frame\n",
    "    FORECAST = 1\n",
    "    \n",
    "    # Convert video frames in gray \n",
    "    VIDEO_TO_GRAY = 0\n",
    "    \n",
    "    REPLACE_ZERO_TO_INFINITELY_SMALL = 0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoLoader():\n",
    "    def __init__(self, config=Config):\n",
    "        self.config = config\n",
    "        self.video = []\n",
    "        self.datasets = {}\n",
    "        \n",
    "        self.R_min_color = 255\n",
    "        self.G_min_color = 255\n",
    "        self.B_min_color = 255\n",
    "        \n",
    "        self.R_max_color = 0\n",
    "        self.G_max_color = 0\n",
    "        self.B_max_color = 0\n",
    "        \n",
    "        self.grey_min_color = 255\n",
    "        self.grey_max_color = 0\n",
    "        \n",
    "    \n",
    "    def normalize(self, frame_orig):\n",
    "        frame = frame_orig.copy().astype(float)\n",
    "        if len(frame.shape) == 3:  # RGB\n",
    "            if self.R_min_color > self.R_max_color:\n",
    "                self.R_min_color, self.R_max_color = self.R_max_color, self.R_min_color\n",
    "            if self.G_min_color > self.G_max_color:\n",
    "                self.G_min_color, self.G_max_color = self.G_max_color, self.G_min_color\n",
    "            if self.B_min_color > self.B_max_color:\n",
    "                self.B_min_color, self.B_max_color = self.B_max_color, self.B_min_color\n",
    "\n",
    "            frame[:,:,0] = (frame[:,:,0] - self.R_min_color) / ((self.R_max_color - self.R_min_color) or 1)\n",
    "            frame[:,:,1] = (frame[:,:,1] - self.G_min_color) / ((self.G_max_color - self.G_min_color) or 1)\n",
    "            frame[:,:,2] = (frame[:,:,2] - self.B_min_color) / ((self.B_max_color - self.B_min_color) or 1)\n",
    "        else:                      # GREY\n",
    "            if self.grey_min_color > self.grey_max_color:\n",
    "                self.grey_min_color, self.grey_max_color = self.grey_max_color, self.grey_min_color\n",
    "            frame = ((frame - self.R_min_color) / ((self.R_max_color - self.R_min_color) or 1)) or REPLACE_ZERO_TO_INFINITELY_SMALL\n",
    "        frame[frame == 0] = self.config.REPLACE_ZERO_TO_INFINITELY_SMALL\n",
    "        return frame\n",
    "            \n",
    "    \n",
    "    def video_to_dataset(self, dataset_name=\"default\", verbose=1):\n",
    "        if dataset_name in self.datasets.keys():\n",
    "            del self.datasets[dataset_name]\n",
    "        \n",
    "        if not len(self.video):\n",
    "            raise Exception('Video not loaded!')\n",
    "    \n",
    "        min_video_len = self.config.FORECAST + self.config.WINDOW_SIZE\n",
    "        if len(self.video) < min_video_len:\n",
    "            raise Exception('Video is short!')\n",
    "            \n",
    "        if verbose:\n",
    "            printProgressBar(0, len(self.video), prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "        self.datasets[dataset_name] = {\"X\":[], \"y\":[]}\n",
    "        windows = []\n",
    "        for i in range(len(self.video)):\n",
    "            frame = self.video[i]\n",
    "            if len(windows) < self.config.WINDOW_SIZE:\n",
    "                windows.append([])\n",
    "\n",
    "            for j in range(len(windows)):\n",
    "                windows[j]\n",
    "                windows[j].append(self.normalize(frame))\n",
    "                if len(windows[j]) == min_video_len:\n",
    "                    self.datasets[dataset_name][\"X\"].append(windows[j][:-1*self.config.FORECAST])\n",
    "                    self.datasets[dataset_name][\"y\"].append(windows[j][-1])\n",
    "                    windows[j] = windows[j][self.config.WINDOW_SIZE:]\n",
    "            if verbose:\n",
    "                printProgressBar(i+1, len(self.video), prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "        return True\n",
    "            \n",
    "    def delete_cache_video(self):\n",
    "        del self.video\n",
    "        self.video = []\n",
    "        \n",
    "        self.R_min_color = 255\n",
    "        self.G_min_color = 255\n",
    "        self.B_min_color = 255\n",
    "        \n",
    "        self.R_max_color = 0\n",
    "        self.G_max_color = 0\n",
    "        self.B_max_color = 0\n",
    "        \n",
    "        self.grey_min_color = 255\n",
    "        self.grey_max_color = 0\n",
    "        return True\n",
    "            \n",
    "    \n",
    "    def load_gen(self, path=None, save_video=1, to_dataset=0, dataset_name=\"default\", verbose=1, batch_size=None):\n",
    "        # delete buffer\n",
    "        self.delete_cache_video()\n",
    "        \n",
    "        # set path\n",
    "        path = path or self.config.DEFAULT_VIDEO_PATH\n",
    "        if verbose:\n",
    "            print(\"Open video path: \", path)\n",
    "            \n",
    "        # prepare\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        if verbose:\n",
    "            print(\"Video have: \",video_length, \" frame\")\n",
    "        \n",
    "        if verbose:\n",
    "            printProgressBar(0, video_length, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "        \n",
    "        # start load video\n",
    "        i = 0\n",
    "        while(cap.isOpened()):\n",
    "            # get frame\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            # exit point\n",
    "            if not ret or i > 50:\n",
    "                break\n",
    "            \n",
    "            # to gray\n",
    "            if self.config.VIDEO_TO_GRAY:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                grey_min_color = np.min(frame)\n",
    "                grey_max_color = np.max(frame)\n",
    "                \n",
    "                if self.grey_min_color > grey_min_color:\n",
    "                    self.grey_min_color = grey_min_color\n",
    "                if self.grey_max_color > grey_max_color:\n",
    "                    self.grey_max_color = grey_max_color\n",
    "            else:\n",
    "                R_min_color = np.min(frame[:,:,0])\n",
    "                G_min_color = np.min(frame[:,:,1])\n",
    "                B_min_color = np.min(frame[:,:,2])\n",
    "\n",
    "                R_max_color = np.max(frame[:,:,0])\n",
    "                G_max_color = np.max(frame[:,:,1])\n",
    "                B_max_color = np.max(frame[:,:,2])\n",
    "                \n",
    "                # R\n",
    "                if self.R_min_color > R_min_color:\n",
    "                    self.R_min_color = R_min_color\n",
    "                if self.R_max_color > R_max_color:\n",
    "                    self.R_max_color = R_max_color\n",
    "                   \n",
    "                # G\n",
    "                if self.G_min_color > G_min_color:\n",
    "                    self.G_min_color = G_min_color\n",
    "                if self.G_max_color > G_max_color:\n",
    "                    self.G_max_color = G_max_color\n",
    "                   \n",
    "                # B\n",
    "                if self.B_min_color > B_min_color:\n",
    "                    self.B_min_color = B_min_color\n",
    "                if self.B_max_color > B_max_color:\n",
    "                    self.B_max_color = B_max_color\n",
    "            \n",
    "            \n",
    "            # save video\n",
    "            if save_video:\n",
    "                self.video.append(frame)\n",
    "            i += 1\n",
    "            printProgressBar(i, video_length, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "        if verbose:\n",
    "            print(\"Close video path: \", path)\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoLoader = VideoLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open video path:  test.mp4\n",
      "Video have:  1442  frame\n",
      "Close video path:  test.mp4----------------------------------| 3.5% Complete\n"
     ]
    }
   ],
   "source": [
    "videoLoader.load_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress: |--------------------------------------------------| 0.0% Complete\r",
      "RGB\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0af21b20f7c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvideoLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-4d5f25454840>\u001b[0m in \u001b[0;36mvideo_to_dataset\u001b[0;34m(self, dataset_name, verbose)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mwindows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mwindows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmin_video_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFORECAST\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4d5f25454840>\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(self, frame_orig)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR_min_color\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR_max_color\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR_min_color\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR_max_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR_max_color\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR_min_color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "videoLoader.video_to_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
